{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91a453ad",
   "metadata": {},
   "source": [
    "Ceci est un fichier Jupyter Notebook.\n",
    "Ce fichier contient mes démarches et explications au devoir.\n",
    "Je, Hossein Hajmirbaba (300208487), ai effectué ce devoir seul.\n",
    "Je suis concient que c'est possible que lorsque vous allez run le program vous allez obtenir des résultats différent. C'est quelques choses que je comprends toujours pas comment je peux faire. Si vous pourriez écrire dans les commentaires de correction pour comment la prochaine fois je peux analyser mes résultats.\n",
    "Merci."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7b62341",
   "metadata": {},
   "source": [
    "# 1. Explication du problème\n",
    "\n",
    "L'objectif principal de ce devoir est d'effectué une étude empirique d'une problème de classification. Ce devoir permettra de me familiriser et comprendre l'implémentation des algorithmes de classification: algorithmes Naives Bayes et Régression logistique."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aedb8249",
   "metadata": {},
   "source": [
    "# 2. Ensemble de donnée\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b03012f-3f03-4f7f-93ed-757d56bbd391",
   "metadata": {},
   "source": [
    "## 2.1 Faire l'importation des librairie nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ca685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d47dc15",
   "metadata": {},
   "source": [
    "## 2.2 Lire l'ensemble de données\n",
    "\n",
    "J'ai choisi l'ensemble de données sur la qualité des vins à partir de la plateforme Kaggle.\n",
    "\n",
    "Voici le lien vers la version raw sur de l'ensemble de données sur Github:\n",
    "https://raw.githubusercontent.com/Hossein1831/KnapSackProblem/main/WineQT.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a5795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/Hossein1831/KnapSackProblem/main/WineQT.csv'\n",
    "dataset = pd.read_csv(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0171b0a2",
   "metadata": {},
   "source": [
    "Regardons quelles sont les colonnes de l'ensemble de données: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf8ffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality', 'Id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da0ddcdf",
   "metadata": {},
   "source": [
    "Les colonnes sont: 'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality' et 'Id'. Sur Kaggle c'est indiqué que les 11 premiers colonnes sont les variables d'entrées et la colonne 'quality' est la variable de sortie.\n",
    "\n",
    "On peut aussi visualiser les 20 premières rangées de l'ensemble de données."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f760c50",
   "metadata": {},
   "source": [
    "## 2.3 Étape de prétraitement\n",
    "\n",
    "Dans cette étape, je vais prétaité l'ensemble de données. La première étape dois toujours être le prétraitement des données. Le prétraitement peut être le nettoyage des données, ordonner les données, enlever des colonnes qui ne sont pas utile, etc.\n",
    "\n",
    "### 2.3.1 Effacer les colonnes n'ont utile\n",
    "\n",
    "Dans l'ensemble de données que j'ai choisi il y a la colonne 'Id' qui n'est pas utile, alors je vais l'effacer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ab72be0",
   "metadata": {},
   "source": [
    "### 2.3.2 Séparation entrée/sortie\n",
    " \n",
    "On peut voir que la colonne 'Id' a était enlever avec succès. Ensuite, j'ai séparé les entrées et les sorties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f954d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputVariables = dataset.iloc[:, 0:11] # Variables qui contient les colonnes pour les variables d'entrée\n",
    "outputVariables = dataset.iloc[:, 11:12] # Variables qui contient les colonnes pour la variable de sortie"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e6a85ea",
   "metadata": {},
   "source": [
    "Nous pouvons visualiser les 10 premières rangées du tableau des entrées:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aaf7981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.097</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides   \n",
       "0            7.4              0.70         0.00             1.9      0.076  \\\n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "5            7.4              0.66         0.00             1.8      0.075   \n",
       "6            7.9              0.60         0.06             1.6      0.069   \n",
       "7            7.3              0.65         0.00             1.2      0.065   \n",
       "8            7.8              0.58         0.02             2.0      0.073   \n",
       "9            6.7              0.58         0.08             1.8      0.097   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates   \n",
       "0                 11.0                  34.0   0.9978  3.51       0.56  \\\n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                 15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                 15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                  9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                 15.0                  65.0   0.9959  3.28       0.54   \n",
       "\n",
       "   alcohol  \n",
       "0      9.4  \n",
       "1      9.8  \n",
       "2      9.8  \n",
       "3      9.8  \n",
       "4      9.4  \n",
       "5      9.4  \n",
       "6      9.4  \n",
       "7     10.0  \n",
       "8      9.5  \n",
       "9      9.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputVariables.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e29154a3",
   "metadata": {},
   "source": [
    "On peut visualiser les 10 premières rangées de la colonne des sorties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187c7eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quality\n",
       "0        5\n",
       "1        5\n",
       "2        5\n",
       "3        6\n",
       "4        5\n",
       "5        5\n",
       "6        5\n",
       "7        7\n",
       "8        7\n",
       "9        5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputVariables.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bebd3acc",
   "metadata": {},
   "source": [
    "### 2.3.3 Visualisation globale\n",
    "\n",
    "On peut également utiliser la méthode `describe()` pour avoir une vu des données. Cette méthode nous montre combien de rangées nous avons, les valeurs minimales et maximale de chaque attributs et autre informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa1c03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.311111</td>\n",
       "      <td>0.531339</td>\n",
       "      <td>0.268364</td>\n",
       "      <td>2.532152</td>\n",
       "      <td>0.086933</td>\n",
       "      <td>15.615486</td>\n",
       "      <td>45.914698</td>\n",
       "      <td>0.996730</td>\n",
       "      <td>3.311015</td>\n",
       "      <td>0.657708</td>\n",
       "      <td>10.442111</td>\n",
       "      <td>5.657043</td>\n",
       "      <td>804.969379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.747595</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>0.196686</td>\n",
       "      <td>1.355917</td>\n",
       "      <td>0.047267</td>\n",
       "      <td>10.250486</td>\n",
       "      <td>32.782130</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.156664</td>\n",
       "      <td>0.170399</td>\n",
       "      <td>1.082196</td>\n",
       "      <td>0.805824</td>\n",
       "      <td>463.997116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.995570</td>\n",
       "      <td>3.205000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>411.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.996680</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>794.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.100000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.997845</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1209.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1597.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar   \n",
       "count    1143.000000       1143.000000  1143.000000     1143.000000  \\\n",
       "mean        8.311111          0.531339     0.268364        2.532152   \n",
       "std         1.747595          0.179633     0.196686        1.355917   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.392500     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.250000        2.200000   \n",
       "75%         9.100000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density   \n",
       "count  1143.000000          1143.000000           1143.000000  1143.000000  \\\n",
       "mean      0.086933            15.615486             45.914698     0.996730   \n",
       "std       0.047267            10.250486             32.782130     0.001925   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             21.000000     0.995570   \n",
       "50%       0.079000            13.000000             37.000000     0.996680   \n",
       "75%       0.090000            21.000000             61.000000     0.997845   \n",
       "max       0.611000            68.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality           Id  \n",
       "count  1143.000000  1143.000000  1143.000000  1143.000000  1143.000000  \n",
       "mean      3.311015     0.657708    10.442111     5.657043   804.969379  \n",
       "std       0.156664     0.170399     1.082196     0.805824   463.997116  \n",
       "min       2.740000     0.330000     8.400000     3.000000     0.000000  \n",
       "25%       3.205000     0.550000     9.500000     5.000000   411.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000   794.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  1209.500000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  1597.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73177928",
   "metadata": {},
   "source": [
    "### 2.3.4 Nombre de valuer nulle\n",
    "\n",
    "Ensuite je vais utiliser la méthode `isnull()` et `sum()` pour vérifier le nombre total de valeurs null dans chaque colonnes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48e338df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "Id                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcee7283",
   "metadata": {},
   "source": [
    "On peut voir qu'aucune colonne contient des valeurs null. Ceci nous facilite un peu la tâche, car nous aurons pas besoin de faire le traitement de donnée **null**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cb1169c",
   "metadata": {},
   "source": [
    "### 2.3.5 Séparation de Entrainer et Tester les models\n",
    "\n",
    "À l'étape **2.3.2** on a séparer les entrées et les sorties. Maintenant on va configurer les variables de *testing* et *training*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ab6511",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputVariables_train, inputVariables_test, outputVariables_train, outputVariables_test = train_test_split(inputVariables, outputVariables, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3539e3d3",
   "metadata": {},
   "source": [
    "### 2.3.6 Mise à l'echelle\n",
    "\n",
    "La mise à l'échelle des caractéristiques est une étape importante dans le prétraitement des données pour les algorithmes d'apprentissage automatique, en particulier ceux qui utilisent des techniques d'optimisation comme la régression logistique. Sans mise à l'échelle, des caractéristiques ayant de grandes valeurs pourraient peser inutilement plus dans le modèle. De plus, cela peut ralentir la convergence des algorithmes d'optimisation et rendre le modèle moins efficace. La mise à l'échelle garantit que toutes les caractéristiques contribuent de manière égale à la performance du modèle et accélère la convergence de l'algorithme.\n",
    "\n",
    "Dans l'ensemble de données que j'ai choisi certains colonnes ont des écarts très grand entre les valeurs et cela peut nuire à l'apprentissage du modèle.\n",
    "\n",
    "Pour mettre à l'échelle l'ensemble de données je vais utiliser la méthode `StandardScaler()` de **scikit-learn**, cela va nous permettre d'optimiser nos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88eca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardScaler = StandardScaler()\n",
    "inputVariables_train_scaled = standardScaler.fit_transform(inputVariables_train)\n",
    "inputVariables_test_scaled = standardScaler.transform(inputVariables_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5c1bcb4",
   "metadata": {},
   "source": [
    "# 3. Implémentation du model régression logistique\n",
    "\n",
    "## 3.1 Qu'est-ce que le model régression logistique\n",
    "\n",
    "La régression logistique est un type d'analyse de régression utilisé pour prédire le résultat d'une variable catégorielle en fonction de variables indépendantes. Dans le contexte de la classification, il est souvent utilisé pour estimer la probabilité qu'un événement se produise ou non. Par exemple, dans l'ensemble de données que j'ai choisi, on pourrait présire si un vin est **bon** ou **mauvais** qualité.\n",
    "\n",
    "## 3.2 Classifier les qualités en catégorie binaire\n",
    "\n",
    "Comme le model regréssion logistique est utilisé pour prédire catégoriquement, dans notre cas on doit configurer les critères qui détermine si la qualité d'un vin est **bon** ou **mauvais**.\n",
    "\n",
    "On va effectuer une transformation de la variable de sortie \"quality\" en une variable catégorique binaire. Tout d'abord, on divise les valeurs de \"quality\" en deux catégories en utilisant les seuils définis dans les variables \"bins\" (2 et 6.5) et les noms de groupe *bad* et *good*. Ensuite, il utilise l'encodeur d'étiquettes pour convertir les catégories en valeurs numériques (0 pour *bad* et 1 pour *good*). Enfin, il affiche les valeurs uniques de la nouvelle variable \"quality\" et les compte pour chaque catégorie. Les 20 premières lignes de l'ensemble de données modifié sont également affichées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f46ff29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.097</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides   \n",
       "0            7.4              0.70         0.00             1.9      0.076  \\\n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "5            7.4              0.66         0.00             1.8      0.075   \n",
       "6            7.9              0.60         0.06             1.6      0.069   \n",
       "7            7.3              0.65         0.00             1.2      0.065   \n",
       "8            7.8              0.58         0.02             2.0      0.073   \n",
       "9            6.7              0.58         0.08             1.8      0.097   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates   \n",
       "0                 11.0                  34.0   0.9978  3.51       0.56  \\\n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                 15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                 15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                  9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                 15.0                  65.0   0.9959  3.28       0.54   \n",
       "\n",
       "   alcohol  quality  Id  \n",
       "0      9.4        0   0  \n",
       "1      9.8        0   1  \n",
       "2      9.8        0   2  \n",
       "3      9.8        0   3  \n",
       "4      9.4        0   4  \n",
       "5      9.4        0   5  \n",
       "6      9.4        0   6  \n",
       "7     10.0        1   7  \n",
       "8      9.5        1   8  \n",
       "9      9.2        0  10  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = (2, 6.5, 8)\n",
    "group_names = ['bad', 'good']\n",
    "dataset['quality'] = pd.cut(dataset['quality'], bins=bins, labels=group_names)\n",
    "dataset['quality'].unique()\n",
    "\n",
    "label_quality = LabelEncoder()\n",
    "dataset['quality'] = label_quality.fit_transform(dataset['quality'])\n",
    "dataset['quality'].value_counts()\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55498a57",
   "metadata": {},
   "source": [
    "On remarque que maintenant au lieu de voir la qualité sur une échelle de 1 à 10, on les visualise simplement par **bon** (1) ou **mauvais** (0).\n",
    "\n",
    "## 3.3 Entrainer le model de regréssion logistique sur les données\n",
    "\n",
    "Dans cette étape nous allons entrainer le model de regréssion logistique sur l'ensemble de données que nous avons prétraité précédemment. \n",
    "\n",
    "### 3.3.1 Entrainer/tester/évaluer avec paramètre par défaut\n",
    "\n",
    "D'abord je vais entrainer le model ensuite le stester à l'aide des méthodes de *k-fold cross validation* et ensuite analyser avec la méthode de *macro/micro*\n",
    "\n",
    "#### Entrainer le model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f405c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegression_default = LogisticRegression(max_iter=100)\n",
    "logisticRegression_default.fit(inputVariables_train_scaled, outputVariables_train.values.ravel()) #Entraîner le modèle avec les données d'entraînement\n",
    "Predictions = logisticRegression_default.predict(inputVariables_test_scaled) #Prédire les données de test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40446c5d",
   "metadata": {},
   "source": [
    "En entrainant le model avec les paramètres de test_size et random_state configurés à leur valeurs par défaut, j'ai atteint une précision de 58.74%. La précision des prédictions est effectivement vraiment bas. Nous devons trouvons une façon d'améliorer les prédictions. Pour faire cela, je vais utiliser la méthode de *k-fold cross validation*. *K-fold cross validation* est une technique utilisée pour évaluer la performance d'un modèle d'apprentissage automatique en divisant l'ensemble de données en k sous-ensembles (*folds*). Le modèle est formé sur k−1 de ces *folds* et testé sur le *fold* restant, en répétant ce processus `k` fois avec différents *folds* utilisés comme ensemble de test à chaque fois. La moyenne de la métrique de performance sur les `k` tests est utilisée comme mesure globale de la performance du modèle.\n",
    "\n",
    "#### Tester (4-fold cross validation & micro/macro)\n",
    "\n",
    "Je vais tester le model que je viens d'entrainer. Je vais d'abord commencer avec en testant avec la technique de *k-fold cross validation* et ensuite à l'aide des moyennes **macro** et **micro**.\n",
    "\n",
    "##### 4-fold cross validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3371fec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La précision moyenne du modèle sur les 4 folds est: 56.78%\n"
     ]
    }
   ],
   "source": [
    "#Calculer la précision du modèle avec la validation croisée à 4-fold\n",
    "crossValidation = cross_val_score(logisticRegression_default, inputVariables, outputVariables, cv=4) \n",
    "\n",
    "#Calculer la précision moyenne du modèle sur les 4 folds\n",
    "meanCrossValScore = np.mean(crossValidation) \n",
    "\n",
    "#Afficher la précision moyenne du modèle sur les 4 folds en pourcentage\n",
    "print(\"La précision moyenne du modèle sur les 4 folds est: %.2f%%\" % (meanCrossValScore * 100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6fafb6-9a0e-4779-8152-388cd2f2291e",
   "metadata": {},
   "source": [
    "##### Micro & macro :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d7d8ea3-f7e8-4585-83ca-3716a6583803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision de moyenne micro: 0.6363636363636364\n",
      "Précision de moyenne macro: 0.30845797720797724\n",
      "Rapelle de moyenne micro:   0.6363636363636364\n",
      "Rapelle de moyenne macro:   0.3035569599740723\n"
     ]
    }
   ],
   "source": [
    "micro_precision = precision_score(outputVariables_test, Predictions, average='micro')\n",
    "macro_precision = precision_score(outputVariables_test, Predictions, average='macro')\n",
    "\n",
    "micro_recall = recall_score(outputVariables_test, Predictions, average='micro')\n",
    "macro_recall = recall_score(outputVariables_test, Predictions, average='macro')\n",
    "\n",
    "print(f\"Précision de moyenne micro: {micro_precision}\")\n",
    "print(f\"Précision de moyenne macro: {macro_precision}\")\n",
    "print(f\"Rapelle de moyenne micro:   {micro_recall}\")\n",
    "print(f\"Rapelle de moyenne macro:   {macro_recall}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb654cf9",
   "metadata": {},
   "source": [
    "### 3.3.2 Entrainer/tester/évaluer avec paramètre de *solver* différent\n",
    "\n",
    "Cette fois je vais refaire les même étapes mais avec des paramètre de régression linéaire différente. Je vais seulement changer le paramètre de `solver` différent. La valeur par défault de cette paramètre est `'lbfgs'`. Je vais configurer une fois la valeur à `'liblinear'` et une autre fois à `'newtong-cg'` et ensuite comparer les résultats avec les tests de *k-folding* et *micro/macro*.\n",
    "\n",
    "#### Entrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d25c82f4-965d-4417-b14b-2b8636c5e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegression_change1 = LogisticRegression(max_iter=100, solver='liblinear') # Valeur de Solver configurer à liblinear\n",
    "logisticRegression_change1.fit(inputVariables_train_scaled, outputVariables_train.values.ravel()) #Entraîner le modèle avec les données d'entraînement\n",
    "Predictions_change1 = logisticRegression_change1.predict(inputVariables_test_scaled) #Prédire les données de test\n",
    "\n",
    "logisticRegression_change2 = LogisticRegression(max_iter=100, solver='newton-cg') # Valeur de Solver configurer à newton-cg\n",
    "logisticRegression_change2.fit(inputVariables_train_scaled, outputVariables_train.values.ravel()) #Entraîner le modèle avec les données d'entraînement\n",
    "Predictions_change2 = logisticRegression_change2.predict(inputVariables_test_scaled) #Prédire les données de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de3882b-094e-44d4-9019-b79592aaba51",
   "metadata": {},
   "source": [
    "#### Tester (4-fold cross validation & micro/macro)\n",
    "\n",
    "Je vais tester le model que je viens d'entrainer. Je vais d'abord commencer avec en testant avec la technique de *k-fold cross validation* et ensuite à l'aide des moyennes **macro** et **micro**.\n",
    "\n",
    "##### 4-fold cross validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8920493-9bc8-43c6-9ad6-2889758fa4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La précision moyenne du modèle (liblinear) sur les 4 folds est: 58.09%\n",
      "La précision moyenne du modèle (newton-cg) sur les 4-folds est: 58.88%\n"
     ]
    }
   ],
   "source": [
    "'''change 1'''\n",
    "#Calculer la précision du modèle avec la validation croisée à 4-fold\n",
    "crossValidation = cross_val_score(logisticRegression_change1, inputVariables, outputVariables, cv=4) \n",
    "#Calculer la précision moyenne du modèle sur les 4 folds\n",
    "meanCrossValScore = np.mean(crossValidation) \n",
    "#Afficher la précision moyenne du modèle sur les 4 folds en pourcentage\n",
    "print(\"La précision moyenne du modèle (liblinear) sur les 4 folds est: %.2f%%\" % (meanCrossValScore * 100)) \n",
    "\n",
    "'''change 2'''\n",
    "#Calculer la précision du modèle avec la validation croisée à 4-fold\n",
    "crossValidation = cross_val_score(logisticRegression_change2, inputVariables, outputVariables, cv=4) \n",
    "#Calculer la précision moyenne du modèle sur les 4 folds\n",
    "meanCrossValScore = np.mean(crossValidation) \n",
    "#Afficher la précision moyenne du modèle sur les 4 folds en pourcentage\n",
    "print(\"La précision moyenne du modèle (newton-cg) sur les 4-folds est: %.2f%%\" % (meanCrossValScore * 100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f9d5f-ff96-423f-90ce-5826ca4b95fd",
   "metadata": {},
   "source": [
    "##### Micro & macro (solver='liblinear'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d0cfaac-2f2b-4f0b-8a54-c8b04d021624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision de moyenne micro: 0.6328671328671329\n",
      "Précision de moyenne macro: 0.3821480831138425\n",
      "Rapelle de moyenne micro:   0.6328671328671329\n",
      "Rapelle de moyenne macro:   0.34569761789013126\n"
     ]
    }
   ],
   "source": [
    "micro_precision = precision_score(outputVariables_test, Predictions_change1, average='micro')\n",
    "macro_precision = precision_score(outputVariables_test, Predictions_change1, average='macro')\n",
    "\n",
    "micro_recall = recall_score(outputVariables_test, Predictions_change1, average='micro')\n",
    "macro_recall = recall_score(outputVariables_test, Predictions_change1, average='macro')\n",
    "\n",
    "print(f\"Précision de moyenne micro: {micro_precision}\")\n",
    "print(f\"Précision de moyenne macro: {macro_precision}\")\n",
    "print(f\"Rapelle de moyenne micro:   {micro_recall}\")\n",
    "print(f\"Rapelle de moyenne macro:   {macro_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe736e45-0c28-4b3b-93b0-7e24c35eaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Micro & macro (solver='newton-cg'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01d26b5b-99a7-4658-bedf-7cf90327fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision de moyenne micro: 0.6363636363636364\n",
      "Précision de moyenne macro: 0.30845797720797724\n",
      "Rapelle de moyenne micro:   0.6363636363636364\n",
      "Rapelle de moyenne macro:   0.3035569599740723\n"
     ]
    }
   ],
   "source": [
    "micro_precision = precision_score(outputVariables_test, Predictions_change2, average='micro')\n",
    "macro_precision = precision_score(outputVariables_test, Predictions_change2, average='macro')\n",
    "\n",
    "micro_recall = recall_score(outputVariables_test, Predictions_change2, average='micro')\n",
    "macro_recall = recall_score(outputVariables_test, Predictions_change2, average='macro')\n",
    "\n",
    "print(f\"Précision de moyenne micro: {micro_precision}\")\n",
    "print(f\"Précision de moyenne macro: {macro_precision}\")\n",
    "print(f\"Rapelle de moyenne micro:   {micro_recall}\")\n",
    "print(f\"Rapelle de moyenne macro:   {macro_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3110e89a-8336-459f-908c-c44ed6d62cd7",
   "metadata": {},
   "source": [
    "### 3.3.3 Entrainer/tester/évaluer avec paramètre de *tol* différent\n",
    "\n",
    "Cette fois je vais refaire les même étapes mais avec des paramètre de régression linéaire différente. Je vais seulement changer le paramètre de `tol` (tolérence) différent. La valeur par défault de cette paramètre est `tol=1e-4`. Je vais configurer une fois la valeur à `tol=1e-1` et une autre fois à `tol=1e-6` et ensuite comparer les résultats avec les tests de *k-folding* et *micro/macro*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7778e4d-0155-4733-a74b-54ccaec5be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegression_change3 = LogisticRegression(max_iter=100, tol=0.1) # Valeur de Solver configurer à liblinear\n",
    "logisticRegression_change3.fit(inputVariables_train_scaled, outputVariables_train.values.ravel()) #Entraîner le modèle avec les données d'entraînement\n",
    "Predictions_change3 = logisticRegression_change3.predict(inputVariables_test_scaled) #Prédire les données de test\n",
    "\n",
    "logisticRegression_change4 = LogisticRegression(max_iter=100, tol=0.000001) # Valeur de Solver configurer à newton-cg\n",
    "logisticRegression_change4.fit(inputVariables_train_scaled, outputVariables_train.values.ravel()) #Entraîner le modèle avec les données d'entraînement\n",
    "Predictions_change4 = logisticRegression_change4.predict(inputVariables_test_scaled) #Prédire les données de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec17472-b7f4-4a78-9a16-6b42fdd2d899",
   "metadata": {},
   "source": [
    "#### Tester (4-fold cross validation & micro/macro)\n",
    "\n",
    "Je vais tester le model que je viens d'entrainer. Je vais d'abord commencer avec en testant avec la technique de *k-fold cross validation* et ensuite à l'aide des moyennes **macro** et **micro**.\n",
    "\n",
    "##### 4-fold cross validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0625578-9351-46d0-97af-99cc84f3c632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La précision moyenne du modèle (tol=0.1) sur les 4 folds est: 56.78%\n",
      "La précision moyenne du modèle (tol=0.000001) sur les 4 folds est: 56.78%\n"
     ]
    }
   ],
   "source": [
    "'''change 3'''\n",
    "#Calculer la précision du modèle avec la validation croisée à 4-fold\n",
    "crossValidation = cross_val_score(logisticRegression_change3, inputVariables, outputVariables, cv=4) \n",
    "#Calculer la précision moyenne du modèle sur les 4 folds\n",
    "meanCrossValScore = np.mean(crossValidation) \n",
    "#Afficher la précision moyenne du modèle sur les 4 folds en pourcentage\n",
    "print(\"La précision moyenne du modèle (tol=0.1) sur les 4 folds est: %.2f%%\" % (meanCrossValScore * 100)) \n",
    "\n",
    "'''change 4'''\n",
    "#Calculer la précision du modèle avec la validation croisée à 4-fold\n",
    "crossValidation = cross_val_score(logisticRegression_change4, inputVariables, outputVariables, cv=4) \n",
    "#Calculer la précision moyenne du modèle sur les 4 folds\n",
    "meanCrossValScore = np.mean(crossValidation) \n",
    "#Afficher la précision moyenne du modèle sur les 4 folds en pourcentage\n",
    "print(\"La précision moyenne du modèle (tol=0.000001) sur les 4 folds est: %.2f%%\" % (meanCrossValScore * 100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe68329-7f53-4cba-b508-28593d78278f",
   "metadata": {},
   "source": [
    "##### Micro & macro tol=1e-1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6eaf32b8-c422-47ee-9e94-2cad8dedfce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision de moyenne micro: 0.6363636363636364\n",
      "Précision de moyenne macro: 0.30845797720797724\n",
      "Rapelle de moyenne micro:   0.6363636363636364\n",
      "Rapelle de moyenne macro:   0.3035569599740723\n"
     ]
    }
   ],
   "source": [
    "micro_precision = precision_score(outputVariables_test, Predictions_change3, average='micro')\n",
    "macro_precision = precision_score(outputVariables_test, Predictions_change3, average='macro')\n",
    "\n",
    "micro_recall = recall_score(outputVariables_test, Predictions_change3, average='micro')\n",
    "macro_recall = recall_score(outputVariables_test, Predictions_change3, average='macro')\n",
    "\n",
    "print(f\"Précision de moyenne micro: {micro_precision}\")\n",
    "print(f\"Précision de moyenne macro: {macro_precision}\")\n",
    "print(f\"Rapelle de moyenne micro:   {micro_recall}\")\n",
    "print(f\"Rapelle de moyenne macro:   {macro_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9596177f-c4a2-4ebd-b544-b3eaa52162d6",
   "metadata": {},
   "source": [
    "##### Micro & Macro tol=1e-6 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3adb122-c571-4125-a46c-e82dd38e4647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision de moyenne micro: 0.6363636363636364\n",
      "Précision de moyenne macro: 0.30845797720797724\n",
      "Rapelle de moyenne micro:   0.6363636363636364\n",
      "Rapelle de moyenne macro:   0.3035569599740723\n"
     ]
    }
   ],
   "source": [
    "micro_precision = precision_score(outputVariables_test, Predictions_change4, average='micro')\n",
    "macro_precision = precision_score(outputVariables_test, Predictions_change4, average='macro')\n",
    "\n",
    "micro_recall = recall_score(outputVariables_test, Predictions_change4, average='micro')\n",
    "macro_recall = recall_score(outputVariables_test, Predictions_change4, average='macro')\n",
    "\n",
    "print(f\"Précision de moyenne micro: {micro_precision}\")\n",
    "print(f\"Précision de moyenne macro: {macro_precision}\")\n",
    "print(f\"Rapelle de moyenne micro:   {micro_recall}\")\n",
    "print(f\"Rapelle de moyenne macro:   {macro_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d125486-19e6-439d-bf23-5af6fc19a58a",
   "metadata": {},
   "source": [
    "# 4. Implémentation du model Naïve Bayes Gaussian\n",
    "\n",
    "## 4.1 Qu'est-ce que le model Naïve Bayes Gaussian\n",
    "\n",
    "J'ai choisi le modèle Naïve Bayes Gaussien qui est une variante de l'algorithme Naïve Bayes utilisée pour les caractéristiques continues. Ce modèle suppose que les valeurs de chaque caractéristique suivent une distribution gaussienne (ou normale). L'algorithme calcule la probabilité de chaque classe pour une observation donnée en utilisant la formule de Bayes et en supposant que les caractéristiques sont indépendantes les unes des autres. Ensuite, il attribue l'observation à la classe ayant la plus grande probabilité. Ce modèle est particulièrement utile pour les tâches de classification rapide et simple.\n",
    "\n",
    "## 4.2 Entrainer/tester/évaluer\n",
    "\n",
    "D'abord je vais entrainer le model ensuite le stester à l'aide des méthodes de *k-fold cross validation* et ensuite analyser avec la méthode de *macro/micro*\n",
    "\n",
    "### 4.2.1 Entrainer/tester/évaluer le model avec paramètre par défault\n",
    "\n",
    "Je vais débuter en entrainant, testant et évaluant le premier modèle qui a des paramètres configurer à leurs valeur par défault.\n",
    "\n",
    "#### Entrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4590dda0-8574-4afc-b2c1-3c32369ef983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Naive Bayes Accuracy :  0.583916083916084\n"
     ]
    }
   ],
   "source": [
    "gaussian_default = GaussianNB()\n",
    "prediction_gaussian_default = gaussian_default.fit(inputVariables_train, outputVariables_train).predict(inputVariables_test)\n",
    "print(\"Default Naive Bayes Accuracy : \", accuracy_score(outputVariables_test, prediction_gaussian_default, normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae2633d-5248-4620-a72a-66417a1d081e",
   "metadata": {},
   "source": [
    "#### Tester\n",
    "\n",
    "Dans cette étape je vais tester le modèle que je viens d'entrainer en utilisant la technique de *k-fold cross validation*\n",
    "\n",
    "##### 4-fold cross valiadtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0aa2434-c518-4842-b167-98987316ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La précision moyenne du modèle sur les 4 folds est: 52.59%\n"
     ]
    }
   ],
   "source": [
    "#Calculer la précision du modèle avec la validation croisée à 4-fold\n",
    "crossValidation = cross_val_score(gaussian_default, inputVariables, outputVariables, cv=4)\n",
    "\n",
    "#Calculer la précision moyenne du modèle sur les 4 folds\n",
    "meanCrossValScore = np.mean(crossValidation) \n",
    "\n",
    "#Afficher la précision moyenne du modèle sur les 4 folds en pourcentage\n",
    "print(\"La précision moyenne du modèle sur les 4 folds est: %.2f%%\" % (meanCrossValScore * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474daaef-4c61-4290-866d-b5708fad3582",
   "metadata": {},
   "source": [
    "#### Évaluer\n",
    "\n",
    "Je vais utiliser la méthode micro/macro des moyenne de rapelle et de précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "391cb87d-3531-4285-bbcd-bdb09005aa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-Average Precision: 0.583916083916084\n",
      "Macro-Average Precision: 0.30468913580349627\n",
      "Micro-Average Recall   : 0.583916083916084\n",
      "Macro-Average Recall   : 0.30051855452924975\n"
     ]
    }
   ],
   "source": [
    "micro_precision = precision_score(outputVariables_test, prediction_gaussian_default, average='micro')\n",
    "macro_precision = precision_score(outputVariables_test, prediction_gaussian_default, average='macro')\n",
    "\n",
    "micro_recall = recall_score(outputVariables_test, prediction_gaussian_default, average='micro')\n",
    "macro_recall = recall_score(outputVariables_test, prediction_gaussian_default, average='macro')\n",
    "\n",
    "print(f\"Micro-Average Precision: {micro_precision}\")\n",
    "print(f\"Macro-Average Precision: {macro_precision}\")\n",
    "print(f\"Micro-Average Recall   : {micro_recall}\")\n",
    "print(f\"Macro-Average Recall   : {macro_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3139c30-0394-41d0-a972-8dc79fef78ec",
   "metadata": {},
   "source": [
    "### 4.2.2 Entrainer/tester/évaluer avec paramètre modifiée\n",
    "\n",
    "Maintenant je vais modifier une des paramètres de la méthode `gaussionNB()`. Je vais modifier le paramètre `var_smoothing`. Par défault cette paramètre est configurer à `var_smoothing=1e-9`. Je vais le configurer une fois à `var_smoothing=1e-1` et une autre fois à `var_smoothing=1e-5`.\n",
    "\n",
    "#### Entrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ecc0edb-e26a-414f-a879-9a41e82267bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy :  0.5174825174825175\n",
      "Naive Bayes Accuracy :  0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "'''change 1'''\n",
    "gaussian_change1 = GaussianNB(var_smoothing=1e-1)\n",
    "prediction_gaussian_change1 = gaussian_change1.fit(inputVariables_train, outputVariables_train).predict(inputVariables_test)\n",
    "print(\"Naive Bayes Accuracy : \", accuracy_score(outputVariables_test, prediction_gaussian_change1, normalize = True))\n",
    "\n",
    "'''change 2'''\n",
    "gaussian_change2 = GaussianNB(var_smoothing=1e-5)\n",
    "prediction_gaussian_change2 = gaussian_change2.fit(inputVariables_train, outputVariables_train).predict(inputVariables_test)\n",
    "print(\"Naive Bayes Accuracy : \", accuracy_score(outputVariables_test, prediction_gaussian_change2, normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63574021-fbc5-4c11-b709-7bc6f7deb45b",
   "metadata": {},
   "source": [
    "#### Tester\n",
    "\n",
    "Dans cette étape je vais tester le modèle que je viens d'entrainer en utilisant la technique de k-fold cross validation.\n",
    "\n",
    "##### 4-fold cross valiadtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38d1ad21-34bd-468c-9963-b4f4bdd32704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La précision moyenne du modèle (1e-1) sur les 4 folds est: 48.20%\n",
      "La précision moyenne du modèle (1e-5) sur les 4 folds est: 54.77%\n"
     ]
    }
   ],
   "source": [
    "#Calculer la précision du modèle avec la validation croisée à 4-fold\n",
    "crossValidation = cross_val_score(gaussian_change1, inputVariables, outputVariables, cv=4)\n",
    "#Calculer la précision moyenne du modèle sur les 4 folds\n",
    "meanCrossValScore = np.mean(crossValidation) \n",
    "#Afficher la précision moyenne du modèle sur les 4 folds en pourcentage\n",
    "print(\"La précision moyenne du modèle (1e-1) sur les 4 folds est: %.2f%%\" % (meanCrossValScore * 100))\n",
    "\n",
    "#Calculer la précision du modèle avec la validation croisée à 4-fold\n",
    "crossValidation = cross_val_score(gaussian_change2, inputVariables, outputVariables, cv=4)\n",
    "#Calculer la précision moyenne du modèle sur les 4 folds\n",
    "meanCrossValScore = np.mean(crossValidation) \n",
    "#Afficher la précision moyenne du modèle sur les 4 folds en pourcentage\n",
    "print(\"La précision moyenne du modèle (1e-5) sur les 4 folds est: %.2f%%\" % (meanCrossValScore * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2572ebe2-1371-43ce-8cf0-853af0c5e644",
   "metadata": {},
   "source": [
    "#### Évaluer \n",
    "\n",
    "Je vais utiliser la méthode de micro/macro pour la analyser les moyenne de rapelle et précision.\n",
    "\n",
    "##### Évaluation pour `gaussian_change1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac6b8f54-a4a3-465d-b320-6ece8c6462ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-Average Precision: 0.5174825174825175\n",
      "Macro-Average Precision: 0.22632045253186125\n",
      "Micro-Average Recall   : 0.5174825174825175\n",
      "Macro-Average Recall   : 0.24462809917355371\n"
     ]
    }
   ],
   "source": [
    "micro_precision = precision_score(outputVariables_test, prediction_gaussian_change1, average='micro')\n",
    "macro_precision = precision_score(outputVariables_test, prediction_gaussian_change1, average='macro')\n",
    "\n",
    "micro_recall = recall_score(outputVariables_test, prediction_gaussian_change1, average='micro')\n",
    "macro_recall = recall_score(outputVariables_test, prediction_gaussian_change1, average='macro')\n",
    "\n",
    "print(f\"Micro-Average Precision: {micro_precision}\")\n",
    "print(f\"Macro-Average Precision: {macro_precision}\")\n",
    "print(f\"Micro-Average Recall   : {micro_recall}\")\n",
    "print(f\"Macro-Average Recall   : {macro_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348dee7-6e1b-4b5d-9921-c528b321650f",
   "metadata": {},
   "source": [
    "##### Évaluation pour `gaussian_change2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a47e18d5-9cc2-41c9-8011-5222ee0a6e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-Average Precision: 0.6153846153846154\n",
      "Macro-Average Precision: 0.30498800959232614\n",
      "Micro-Average Recall   : 0.6153846153846154\n",
      "Macro-Average Recall   : 0.31291524874412574\n"
     ]
    }
   ],
   "source": [
    "micro_precision = precision_score(outputVariables_test, prediction_gaussian_change2, average='micro')\n",
    "macro_precision = precision_score(outputVariables_test, prediction_gaussian_change2, average='macro')\n",
    "\n",
    "micro_recall = recall_score(outputVariables_test, prediction_gaussian_change2, average='micro')\n",
    "macro_recall = recall_score(outputVariables_test, prediction_gaussian_change2, average='macro')\n",
    "\n",
    "print(f\"Micro-Average Precision: {micro_precision}\")\n",
    "print(f\"Macro-Average Precision: {macro_precision}\")\n",
    "print(f\"Micro-Average Recall   : {micro_recall}\")\n",
    "print(f\"Macro-Average Recall   : {macro_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1568e8-4bcd-413d-9ecc-b583d1bee27d",
   "metadata": {},
   "source": [
    "# 5. Analyse et comparaison des résulats obtenus selon les modèles entrainés\n",
    "\n",
    "Dans cette étape je vais analyser les résultats obtenus et de comprendre leurs signification, et ensuite les comparer avec d'autre résultats où certains paramètres étaient modifées.\n",
    "\n",
    "J'ai entrainer deux modèles sur un même ensemble de données. J'ai choisi les modèles de **regréssion linéaire** et **Naïves Bayes Gaussian**. Pour le premier entrainement de chaque modèle j'ai utiliser les modèles configurés à leurs paramètres par défault. J'ai ensuite effectué un testing en utilisant la technique de *k-fold cross-validation* avec `k = 4` et ensuite j'ai évaluer les modèles en utilisant les moyennes *micro* et *macro* de rapelle et précision. Par la suite, j'ai effectué les même étapes pour des modèles avec des paramètres modifiées pour expérimenter et de mieux comprendre l'impact des paramètres et des modèles.\n",
    "\n",
    "## 5.1 Analyse du modèle de regréssion linéaire avec les paramètres par défault\n",
    "\n",
    "### Entrainement\n",
    "\n",
    "J'ai entrainer le modèle avec les paramètres configurées à leurs valeurs par défault.\n",
    "\n",
    "### Tester\n",
    "\n",
    "J'ai utilisé la technique de *k-fold cross-validation* avec `k = 4`. J'ai obtenu le résultat suivant: \n",
    "```\n",
    "La précision moyenne du modèle sur les 4 folds est: 56.78%.\n",
    "```\n",
    "Cela représente la capacité du modèle à bien généraliser sur de nouvelles données. Par contre, une valeur de `56.78%` signifie que le modèle est plutôt mauvais. Plusieurs facteurs peuvent avoir causer l'obtention d'une valeur si bas. Notamment, la configuration des paramètres du modèle à leurs valeurs par défaut. Cela peut indiquer que configurer certains paramètres à leurs valeurs par défault ne soient pas adaptés pour ce problème. \n",
    "\n",
    "### Évaluation \n",
    "\n",
    "J'ai utilisé la technique des moyennes *micro* et *macro* de rapelle et précision. Et j'ai obtenu les résultats suivantes:\n",
    "```\n",
    "Précision de moyenne micro: 0.6363636363636364\n",
    "Précision de moyenne macro: 0.30845797720797724\n",
    "Rapelle de moyenne micro:   0.6363636363636364\n",
    "Rapelle de moyenne macro:   0.3035569599740723\n",
    "```\n",
    "**Précision de moyenne micro** et **Rapelle de moyenne micro** sont identiques. Cela peut arriver quand la distribution des classes est relativement uniforme, ou quand les erreurs dans les différentes classes se compensent mutuellement. Les valeurs faibles de **précision de moyenne macro** et **rapelle de moyenne macro** suggèrent que le modèle a du mal à classer certaines classes, ce qui peut arriver en présence de classes déséquilibrées ou moins représentées. La **précision de moyenne micro** est plus élevée que la **précision de moyenne macro** ca veut dire que le modèle est probablement bon pour les classes majoritaires mais pas aussi bon pour les classes minoritaires.\n",
    "\n",
    "## 5.2 Analyse du modèle de regréssion linéaire avec paramètre de `solver` différent\n",
    "\n",
    "### Entrainement\n",
    "\n",
    "Cette fois j'ai modifié le paramètre `solver`. J'y ai donné deux valeurs différente que celui par défaut. Par défaut, la valeur est `solver='lbfgs'` et j'ai implémenté une fois avec `solver='liblinear'` et une fois avec `solver='newton-cg'`.\n",
    "\n",
    "### Tester\n",
    "\n",
    "J'ai utilisé la technique de *k-fold cross-validation* avec `k = 4` pour chaque implémentation. J'ai obtenu les résultats suivants:\n",
    "```\n",
    "La précision moyenne du modèle (liblinear) sur les 4 folds est: 58.09% \n",
    "La précision moyenne du modèle (newton-cg) sur les 4 folds est: 58.88%\n",
    "``` \n",
    "Dans mes tests, les `solver` `liblinear` et `newton-cg` ont produit des résultats de précision assez similaires en validation croisée. On peut dire que dans ce cas, le `solver='newton-cg'` a mieux performer que `solver='liblinear'`. Même si les valeurs obtenus sont plus élevé que le résultat obtenu avec le paramètre par défaut `56.78%`, il n'y a pas une si grande différence. Ce qui suggère que le choix du `solver` n'a pas un impact significatif sur cet ensemble de données.\n",
    "\n",
    "### Évaluation\n",
    "\n",
    "J'ai utilisé la technique des moyennes *micro* et *macro* de rapelle et précision pour chacun des implémentations. Et j'ai obtenu les résultats suivantes:\n",
    "```\n",
    "**Qaund solver='liblinear'**\n",
    "Précision de moyenne micro: 0.6328671328671329\n",
    "Précision de moyenne macro: 0.3821480831138425\n",
    "Rapelle de moyenne micro:   0.6328671328671329\n",
    "Rapelle de moyenne macro:   0.34569761789013126\n",
    "\n",
    "**Quand solver='newton-cg'**\n",
    "Précision de moyenne micro: 0.6363636363636364\n",
    "Précision de moyenne macro: 0.30845797720797724\n",
    "Rapelle de moyenne micro:   0.6363636363636364\n",
    "Rapelle de moyenne macro:   0.3035569599740723\n",
    "``` \n",
    "Les mesures de précision et de rappel *micro* sont également similaires, indiquant que les deux solveurs sont presque également efficaces sur l'ensemble des échantillons. Cependant, les mesures *macro* varient, montrant des différences dans la manière dont les solveurs traitent les différentes classes. La similarité des résultats entre les solveurs spécifiés et le `solver` par défaut indique que le problème est assez bien conditionné pour que différents algorithmes d'optimisation arrivent à des solutions comparables.\n",
    "\n",
    "## 5.3 Analyse du modèle de regréssion linéaire avec paramètre de `tol` différent\n",
    "\n",
    "### Entrainer\n",
    "\n",
    "Cette fois j'ai modifié le paramètre `tol`. J'y ai donné deux valeurs différente que celui par défaut. Par défaut, la valeur est `tol=1e-4` et j'ai implémenté une fois avec `tol=1e-1` et une fois avec `tol=1e-6`.\n",
    "\n",
    "### Tester\n",
    "\n",
    "J'ai utilisé la technique de *k-fold cross-validation* avec `k = 4` pour chaque implémentation. J'ai obtenu les résultats suivants:\n",
    "```\n",
    "La précision moyenne du modèle (tol=0.1) sur les 4 folds est: 56.78%\n",
    "La précision moyenne du modèle (tol=0.000001) sur les 4 folds est: 56.78%\n",
    "```\n",
    "Les deux modèles de régression logistique avec différentes valeurs de tolérance (tol=0.1 et tol=0.000001) ont produit des résultats identiques en termes de précision en validation croisée (56,78%).\n",
    "\n",
    "### Évaluer\n",
    "\n",
    "J'ai utilisé la technique des moyennes *micro* et *macro* de rapelle et précision pour chacun des implémentations. Et j'ai obtenu les résultats suivantes:\n",
    "```\n",
    "**Quand tol=1e-1** :\n",
    "Précision de moyenne micro: 0.6363636363636364\n",
    "Précision de moyenne macro: 0.30845797720797724\n",
    "Rapelle de moyenne micro:   0.6363636363636364\n",
    "Rapelle de moyenne macro:   0.3035569599740723\n",
    "\n",
    "**Quand tol=1e-6** :\n",
    "Précision de moyenne micro: 0.6363636363636364\n",
    "Précision de moyenne macro: 0.30845797720797724\n",
    "Rapelle de moyenne micro:   0.6363636363636364\n",
    "Rapelle de moyenne macro:   0.3035569599740723\n",
    "```\n",
    "Les deux modèles de régression logistique avec différentes valeurs de tolérance (tol=0.1 et tol=0.000001) ont produit des résultats identiques en termes de précision en validation croisée (56,78%) et en précision et rappel micro et macro. Cela suggère que la tolérance, qui est le critère d'arrêt pour le solveur, n'a pas eu d'impact significatif sur les performances du modèle pour cet ensemble de données. Le fait que ces résultats soient également identiques à ceux obtenus avec la tolérance par défaut indique que la valeur par défaut de la tolérance dans scikit-learn est probablement déjà bien adaptée pour ce problème. La précision en validation croisée de 56,78% donne une idée de la performance généralisée du modèle, tandis que les mesures de précision et de rappel micro et macro reflètent la performance du modèle sur les différentes classes.\n",
    "\n",
    "## 5.4 Analyse du modèle de Naïves Bayes Gaussian avec paramètre par défault\n",
    "\n",
    "### Entrainer\n",
    "\n",
    "J'ai entrainer le modèle avec les paramètres configurées à leurs valeurs par défault.\n",
    "\n",
    "### Tester\n",
    "\n",
    "J'ai utilisé la technique de *k-fold cross-validation* avec `k = 4`. J'ai obtenu le résultat suivant: \n",
    "```\n",
    "La précision moyenne du modèle sur les 4 folds est: 52.59%.\n",
    "```\n",
    "La précision moyenne de 52.59% obtenue par la validation croisée à 4 folds indique que le modèle Naïve Bayes Gaussien est moins performant que les modèles de régression logistique précédents. Cela pourrait être dû à la distribution des données ou à la manière dont Naïve Bayes traite les caractéristiques.\n",
    "\n",
    "### Évaluer\n",
    "\n",
    "J'ai utilisé la technique des moyennes *micro* et *macro* de rapelle et précision. Et j'ai obtenu les résultats suivantes:\n",
    "```\n",
    "Micro-Average Precision: 0.583916083916084\n",
    "Macro-Average Precision: 0.30468913580349627\n",
    "Micro-Average Recall   : 0.583916083916084\n",
    "Macro-Average Recall   : 0.30051855452924975\n",
    "```\n",
    "La précision et le rappel \"micro-moyens\" sont identiques (environ 58.39%), ce qui signifie que le modèle a une performance générale assez cohérente sur tous les échantillons. Le fait que les mesures \"micro\" et \"macro\" ne soient pas les mêmes indique également que la distribution des classes dans les données n'est probablement pas uniforme.\n",
    "\n",
    "## 5.5 Analyse du modèle de Naïves Bayes Gaussian avec paramètre de `var_smoothing` différent\n",
    "\n",
    "### Entrainer\n",
    "\n",
    "Cette fois j'ai modifié le paramètre `var_smoothing`. J'y ai donné deux valeurs différente que celui par défaut. Par défaut, la valeur est `var_smoothing=1e-9` et j'ai implémenté une fois avec `var_smoothing=1e-1` et une fois avec `var_smoothing=1e-5`.\n",
    "\n",
    "### Tester\n",
    "\n",
    "J'ai utilisé la technique de *k-fold cross-validation* avec `k = 4` sur les deux modèles. J'ai obtenu le résultat suivant: \n",
    "```\n",
    "La précision moyenne du modèle (1e-1) sur les 4 folds est: 48.20%\n",
    "La précision moyenne du modèle (1e-5) sur les 4 folds est: 54.77%\n",
    "```\n",
    "La précision moyenne obtenue en validation croisée à 4-folds varie en fonction de la valeur de `var_smoothing`. Avec `1e-1`, elle est de `48.20%`, et avec `1e-5`, elle monte à `54.77%`. Cela suggère que la valeur de `var_smoothing=1e-5` est plus adaptée à vos données. \n",
    "Parce que ce dernier a une meilleure *cross-validation* que la valeur par défaut.\n",
    "\n",
    "### Évaluer\n",
    "\n",
    "J'ai utilisé la technique des moyennes *micro* et *macro* de rapelle et précision pour chacun des implémentations. Et j'ai obtenu les résultats suivantes:\n",
    "\n",
    "**Quand `var_smoothing = 1e-1`**:\n",
    "```\n",
    "Micro-Average Precision: 0.5174825174825175\n",
    "Macro-Average Precision: 0.22632045253186125\n",
    "Micro-Average Recall   : 0.5174825174825175\n",
    "Macro-Average Recall   : 0.24462809917355371\n",
    "```\n",
    "**Quand `var_smoothing = 1e-5`**:\n",
    "```\n",
    "Micro-Average Precision: 0.6153846153846154\n",
    "Macro-Average Precision: 0.30498800959232614\n",
    "Micro-Average Recall   : 0.6153846153846154\n",
    "Macro-Average Recall   : 0.31291524874412574\n",
    "```\n",
    "La précision et le rappel micro-moyens sont les mêmes dans chaque cas, indiquant une performance globale cohérente sur l'ensemble du jeu de données. Cependant, ces valeurs augmentent lorsque `var_smoothing` passe de `1e-1` à `1e-5`. Les précisions et rappels **macro-moyens** sont également plus faibles que les **micro-moyens**, mais ils s'améliorent également lorsque `var_smoothing` est réduit de `1e-1` à `1e-5`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb46f8e8-61f7-4e5e-81eb-a20c77e234c6",
   "metadata": {},
   "source": [
    "# 6. Conclusion\n",
    "\n",
    "En conclusion, selon le *4-fold cross validation* les deux modèles sont proches. Selon mes données et les paramètres que j'ai modifié, le modèle de regréssion linéaire avec le paramètre de `solver` configurer à `newton-cg` a obtenu le meilleur moyenne de *cross-validation*. Ceci est pouvais être différent si j'avais changer d'autres paramètres. Par contre, en analysant les précisions et rapelles de **macro** et **micro** j'ai remarqué que tous les diférent configuration du modèle de **régression linéaire** ont mieux performé que les modèles de **Naïves Bayes Gaussian**. Seul le modèle de **Naïves Bayes Gaussian** avec le paramètre de `var_smoothing = 1e-5` a performé au même niveau que les modèles de **rgréssion linéaire**. J'ai obtenu des valeurs plus grands dans les moyennes **micro** et des valeurs plus petite dans les moyennes **macro**, cela démontre que mes modèles performent mieux sur les classes majoritaire mais pas nécessairement sur les classes minoritaire. Les ***classes majoritaires** sont celles qui ont le plus grand nombre d'échantillons dans l'ensemble de données, dans mon cas ce sont les données classé comme **mauvais**. Les **classes minoritaires** sont celles qui ont le plus petit nombre d'échantillons dans l'ensemble de données, dans mon cas les données classées comme **bon**. Ceci peut être un grand problème parce que le système va être biasé à classer les vins comme mauvais, même si les attributs du vin sont orientés plus vers un bon vin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df0d2d-d750-46a9-9eb7-5483afbf8ccb",
   "metadata": {},
   "source": [
    "# 7. Référence\n",
    "\n",
    "Youtube -> Simplilearn: Scikit-Learn Tutorial | Machine Learning With Scikit-Learn | Sklearn | Python Tutorial | Simplilearn\n",
    "\n",
    "Link -> https://youtu.be/0Lt9w-BxKFQ?si=da-s3zA8qmW9e8bB\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "Youtube -> Bevan Smith 2: IML28: Logistic regression (part 1): Introduction\n",
    "\n",
    "Link -> https://youtu.be/vOl_pKenYTY?si=o8hkqGqUDrxQGSQ_\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "Youtube -> The AI & DS Channel: Wine quality prediction using logistic regression | Machine Learning Project 3\n",
    "\n",
    "Link -> https://youtu.be/UkzV1e4tRyk?si=Xzb50QQTOJtPPLYX\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "Youtube -> Bevan Smith 2: ML9: How to train and test a simple model using Scikit-learn in Jupyter Notebook (part 1)\n",
    "\n",
    "Link -> https://youtu.be/bXB3xYh9LeA?si=gF_IZIonZmE4Hjxg\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "Youtube -> Bevan Smith 2: ML9: How to train and test a simple model using Scikit-learn in Jupyter Notebook (part 2)\n",
    "\n",
    "Link -> https://youtu.be/MQPZ3arjLLg?si=ehebA5ZBbwnJSRUF\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "Site web -> sklearn.linear_model.LogisticRegression\n",
    "\n",
    "Link -> https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "Site web -> scikit-learn: 1.9. Naive Bayes\n",
    "\n",
    "Link -> https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "Site web -> sklearn.naive_bayes.GaussianNB\n",
    "\n",
    "Link -> https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "Site web -> Kaggle: Wine Quality Dataset\n",
    "\n",
    "Link -> https://www.kaggle.com/datasets/yasserh/wine-quality-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2c5aa-2e15-4eaf-908d-d0e510773238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
